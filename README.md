# ğŸ§  Airflow ML Training Pipeline

Ce projet met en place un pipeline de machine learning orchestrÃ© avec **Apache Airflow**, exÃ©cutÃ© dans un environnement **DockerisÃ©**, et connectÃ© Ã  une base de donnÃ©es **PostgreSQL**. Il automatise la prÃ©paration des donnÃ©es, l'entraÃ®nement d'un modÃ¨le, et la gestion des erreurs avec alertes email.

---

## ğŸ“ Structure du projet

```bash

Dag_Airflow_ML/
â”œâ”€â”€ dags/
â”‚ â”œâ”€â”€ train_model_dag.py # DAG principal orchestrant le pipeline ML
â”‚ â”œâ”€â”€ get-data.py # Script de rÃ©cupÃ©ration des donnÃ©es
â”‚ â””â”€â”€ ml_tasks.py # Fonctions Python : entraÃ®nement, crÃ©ation de tables, Ã©chec simulÃ©
â”‚
â”œâ”€â”€ config/
â”‚ â””â”€â”€ airflow.cfg # Configuration Airflow personnalisÃ©e
â”‚
â”œâ”€â”€ data/
â”‚ â””â”€â”€ advertising.csv # Jeu de donnÃ©es source pour lâ€™entraÃ®nement
â”‚
â”œâ”€â”€ logs/ # Logs gÃ©nÃ©rÃ©s par Airflow (crÃ©Ã©s au runtime)
â”‚
â”œâ”€â”€ ml_logistical_regression/
â”‚ â””â”€â”€ train_model.py # Script dâ€™entraÃ®nement du modÃ¨le de rÃ©gression logistique
â”‚
â”œâ”€â”€ output/
â”‚ â””â”€â”€ model.pkl # ModÃ¨le entraÃ®nÃ© sauvegardÃ©
â”‚
â”œâ”€â”€ plugins/ # Plugins Airflow personnalisÃ©s
â”‚
â”œâ”€â”€ requirements.txt # DÃ©pendances Python (Airflow, providers, etc.)
â”œâ”€â”€ docker-compose.yaml # Stack Docker : Airflow, Postgres, Redis, etc.
â”œâ”€â”€ .env # Variables dâ€™environnement (si utilisÃ©)
â”œâ”€â”€ .venv/ # Environnement virtuel Python (non versionnÃ©)
â”œâ”€â”€ README.md # Documentation du projet
â””â”€â”€ .gitignore # Fichiers/dossiers Ã  exclure du versionnement

```

---

## ğŸš€ FonctionnalitÃ©s

- CrÃ©ation automatique de tables dans PostgreSQL (`intermediate_data`, `intermediate_data_temp`)
- EntraÃ®nement dâ€™un modÃ¨le ML via une fonction Python personnalisÃ©e
- Simulation dâ€™Ã©chec pour tester lâ€™envoi dâ€™email
- Notifications par email en cas dâ€™Ã©chec ou de succÃ¨s
- Architecture modulaire avec `PythonOperator` et `PostgresHook`

---

## âš™ï¸ PrÃ©requis

- Python 3.12
- Docker & Docker Compose
- Apache Airflow 3.1
- Provider PostgreSQL : `apache-airflow-providers-postgres==6.3.0`

---

## ğŸ› ï¸ Installation

```bash
# 1. Cloner le projet
git clone <url-du-repo>
cd Dag_Airflow_ML

# 2. CrÃ©er un environnement virtuel
python -m venv .venv
source .venv/bin/activate

# 3. Installer les dÃ©pendances
pip install -r requirements.txt

# 4. Lancer les services Airflow + Postgres
docker compose up --build
```

## ğŸŒ Interface Airflow

- AccÃ¨s via navigateur : http://localhost:8080 Identifiants par dÃ©faut :
- Login : airflow
- Mot de passe : airflow

## ğŸ§ª DÃ©clencher le DAG

```bash
docker compose exec airflow-scheduler airflow dags trigger train_model_dag
```

Ou via lâ€™interface Airflow â†’ DAGs â†’ train_model_dag â†’ â–¶ï¸

## ğŸ“¬ Notifications email

- En cas dâ€™Ã©chec, un email est envoyÃ© Ã  : ...@gmail.com
- SMTP doit Ãªtre configurÃ© dans airflow.cfg ou via les variables dâ€™environnement

## âš ï¸ ProblÃ¨mes frÃ©quents

- ***Erreur : `Connection refused` vers Postgres**  
  â†’ VÃ©rifier que le service `postgres` est bien lancÃ© dans Docker.

- ***Airflow ne trouve pas le DAG**  
  â†’ VÃ©rifier que le dossier `dags/` est bien montÃ© dans `docker-compose.yaml`.

## ğŸ”® Ã‰volutions prÃ©vues

- IntÃ©gration dâ€™un modÃ¨le de validation automatique des performances
- Ajout dâ€™un dashboard Streamlit pour visualiser les rÃ©sultats
- Automatisation du dÃ©ploiement du modÃ¨le entraÃ®nÃ©

## ğŸ‘©â€ğŸ’» Auteur

Projet dÃ©veloppÃ© par Amina dans le cadre de sa reconversion professionnelle en data/ML. Objectif : maÃ®triser lâ€™orchestration de workflows ML avec Airflow + Docker + PostgreSQL.